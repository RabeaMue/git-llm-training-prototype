{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19391e9c-5345-4092-9f2c-7937c35f2564",
   "metadata": {},
   "source": [
    "# Git LLM Training Prototype\n",
    "\n",
    "A retrieval-based QA prototype for personalized Git training using LlamaIndex and Library Carpentry content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc7444-d401-4e0e-8c72-c706b20d84a5",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates a prototype for a personalized, LLM-assisted Git training system. \n",
    "It uses the [LlamaIndex](https://www.llamaindex.ai/) framework and a small dataset of questions and answers based on the [Library Carpentry Git Lesson](https://librarycarpentry.github.io/lc-git/instructor/aio.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbcf2d63-f00c-4460-adea-c61a2d6a1705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "# !pip install llama-index sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191892db-6203-4ed2-82b4-0b38416ca112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Answer: Context information is below.\n",
      "---------------------\n",
      "Q: Why do I need to use 'git add' before 'git commit'?\n",
      "A: 'git add' tells Git which changes you want to include in the next commit. This allows you to control what goes into the project history.\n",
      "\n",
      "Q: What is Git and why is it useful in research?\n",
      "A: Git is a version control system that helps track changes in files. In research, it ensures reproducibility, documents development history, and facilitates collaboration.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: Why do I need to use git add before committing?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import json\n",
    "\n",
    "# Load training data\n",
    "with open(\"git_llm_training_data.json\", \"r\") as f:\n",
    "    qa_pairs = json.load(f)\n",
    "\n",
    "# Convert to documents\n",
    "documents = [Document(text=f\"Q: {item['prompt']}\\nA: {item['response']}\") for item in qa_pairs]\n",
    "\n",
    "# Set up embedding model (globally via Settings)\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = None  # Disable LLM (retrieval only)\n",
    "\n",
    "# Create index and query engine\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Test query\n",
    "response = query_engine.query(\"Why do I need to use git add before committing?\")\n",
    "print(\"Answer:\", response.response.strip())\n",
    "\n",
    "# Interactive query loop (stop with 'exit')\n",
    "#while True:\n",
    "#    user_input = input(\"Ask a Git question (or type 'exit'): \")\n",
    "#    if user_input.lower().strip() == \"exit\":\n",
    "#        break\n",
    "#    response = query_engine.query(user_input)\n",
    "#    print(\"Answer:\", response.response.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a4924-52a8-400d-921d-396132162281",
   "metadata": {},
   "source": [
    "## Part 2: LLM-Generated Answers using Phi via Ollama\n",
    "\n",
    "This section demonstrates how to integrate a local open-source LLM (Phi-2) into the prototype using [Ollama](https://ollama.com/).\n",
    "The LLM generates context-aware answers based on the same retrieval mechanism used before.\n",
    "\n",
    "Unlike the retrieval-only prototype, the model now produces full responses rather than returning the most similar stored answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac63871-96af-4b11-8477-d579115ff97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-generated answer: Git add tells Git which changes you want to include in the next commit. This allows you to control what goes into the project history. Without using 'git add', your commits may contain outdated or unwanted information, leading to confusion and errors when reviewing previous versions of your work. Additionally, using 'git add' helps ensure that all relevant files are included in your commits, making it easier for others to understand and maintain your codebase.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a Git question (or type 'exit'):  What does git log do?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-generated answer: Git log is a command that displays a history of all the changes made to the repository over time. It shows a chronological record of every commit, including the author's name, timestamp, message, and the files involved in the commit. This information helps researchers to understand how the code has evolved and to identify which parts may need further testing or refinement. Additionally, git log can be used to revert changes if necessary or roll back to previous versions if a problem arises.\n"
     ]
    }
   ],
   "source": [
    "# Import LLM connector for Ollama\n",
    "from llama_index.llms.ollama import Ollama\n",
    "# Switch to LLM mode: use phi via Ollama\n",
    "Settings.llm = Ollama(model=\"phi\")\n",
    "# Re-create query engine (now with LLM)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Test: LLM-generated response\n",
    "response = query_engine.query(\"Why do I need to use git add before committing?\")\n",
    "print(\"LLM-generated answer:\", response.response.strip())\n",
    "# Interactive loop using phi\n",
    "while True:\n",
    "    user_input = input(\"Ask a Git question (or type 'exit'): \")\n",
    "    if user_input.lower().strip() == \"exit\":\n",
    "        break\n",
    "    response = query_engine.query(user_input)\n",
    "    print(\"LLM-generated answer:\", response.response.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc33491-16ad-4778-a537-fb622f3aa211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-env)",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
